{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Flatten,Dense,MaxPooling2D,Dropout\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ipywidgets as widgets\nimport io\nfrom PIL import Image\nimport tqdm\nfrom sklearn.model_selection import train_test_split\nimport cv2\nfrom sklearn.utils import shuffle\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Combine both testing and training data from the given datasets, then you shuffle them and get rid of any bais if it has.**","metadata":{}},{"cell_type":"code","source":"X=[]\nY=[]\nlabels=['glioma', 'meningioma','notumor','pituitary']\nimage_size=150\n\nfor i in labels:\n        folderPath=os.path.join('/kaggle/input/brain-tumor-mri-dataset/Training',i)\n        for j in os.listdir(folderPath):\n                img=cv2.imread(os.path.join(folderPath,j))\n                img=cv2.resize(img,(image_size,image_size))\n                X.append(img)\n                Y.append(i)\n            \nfor i in labels:\n        folderPath=os.path.join('/kaggle/input/brain-tumor-mri-dataset/Testing',i)\n        for j in os.listdir(folderPath):\n                img=cv2.imread(os.path.join(folderPath,j))\n                img=cv2.resize(img,(image_size,image_size))\n                X.append(img)\n                Y.append(i)\n\n  \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train Test Split\n","metadata":{}},{"cell_type":"markdown","source":"**Lets Convert list into numpy array for computation**","metadata":{}},{"cell_type":"code","source":"X=np.array(X)\nY=np.array(Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Lets shuffle\n\nX,Y=shuffle(X,Y,random_state=100)\nX.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets do the split of dataset for training and for testing\n\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's convert y_train and y_test into categorical data\n#for y_train\ny_train_new=[]\nfor i in y_train:\n    y_train_new.append(labels.index(i))\n    \ny_train=y_train_new\ny_train=tf.keras.utils.to_categorical(y_train)\n\n#for y_test\ny_test_new=[]\nfor i in y_test:\n    y_test_new.append(labels.index(i))\ny_test=y_test_new\ny_test=tf.keras.utils.to_categorical(y_test)\n\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Now,we have compeleted the data manipulation.","metadata":{}},{"cell_type":"markdown","source":"**Model Building**","metadata":{}},{"cell_type":"markdown","source":"**Let's Create the CNN architecture for classification**","metadata":{}},{"cell_type":"code","source":"from keras.layers import Flatten,Dense\nfrom keras.models import Model, load_model\nfrom keras.applications.resnet import ResNet\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.ResNet152(weights = 'imagenet', include_top = False, input_shape = (150,150,3))\nfor layer in base_model.layers:\n  layer.trainable = False\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's base layer with our custom layers\nX=Flatten()(base_model.output)\n# X=Dense(units=150,activation='relu')(X)\n# X=Dense(units=1600,activation='relu')(X)\nresult=Dense(4,activation='softmax')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Model(inputs=base_model.input,outputs=result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss=keras.losses.categorical_crossentropy,metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preparing our data using Data Generator**","metadata":{}},{"cell_type":"code","source":"# def preprocessingImages(path):\n\n# \"\"\"\n# input = Path\n# output=Pre processed images\n# \"\"\"\n# image_data=ImageDataGenerator(zoom_range=0.2,rescale=1/255,horizontal_flip=True)\n# image=image_data.flow_from_directory(directory=path,target_size=(150,150),class_mode=\"categorical\")\n# return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data=preprocessingImages()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Early Stopping and model check point**","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint,EarlyStopping\n\n#early stopping\nes=EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=6, verbose=1,mode='auto')\nmc=ModelCheckpoint(monitor=\"val_accuracy\",filepath=\"./bestmodel.h5\",verbose=1,save_best_only=True,mode='auto')\ncd=[es,mc]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Training**","metadata":{}},{"cell_type":"code","source":"hs=model.fit(X_train,y_train,epochs=30, validation_split=0.2, callbacks=cd)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Model Graphical Interpertation**","metadata":{}},{"cell_type":"code","source":"h=hs.history\nh.keys()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For Accuracy\nimport matplotlib.pyplot as plt\n\nepochs=range(len(h['loss']))\n\nplt.plot(epochs,h['accuracy'],c=\"blue\",label=\"accuracy\")\nplt.plot(epochs,h['val_accuracy'],c=\"green\",label=\"val_accuracy\")\nplt.legend(loc='upper left')\n\nplt.title(\"Accuracy Vs Validation Accuracy\",)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#For Loss\nepochs=range(len(h['loss']))\nplt.plot(epochs,h['loss'],c=\"blue\",label=\"loss\")\nplt.plot(epochs,h['val_loss'],c=\"green\",label=\"val_loss\")\nplt.legend(loc='upper left')\nplt.title(\"Loss Vs Validation Loss\",)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Accuracy**","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\n\nmodel=load_model(\"/kaggle/working/bestmodel.h5\")  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Evaluate on test data\")\nresults = model.evaluate(X_test, y_test, batch_size=32)\nprint(\"test loss, test acc:\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Prediction**","metadata":{}},{"cell_type":"code","source":"mri_image=\"/kaggle/input/brain-tumor-classification-mri/Testing/pituitary_tumor/image(15).jpg\"\nimg=cv2.imread(mri_image)\nimg=cv2.resize(img,(image_size,image_size))\nimg_array=np.array(img)\n\nimg_array.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_array=img.reshape(1,150,150,3)\nimg_array.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimg=image.load_img(mri_image)\nplt.imshow(img,interpolation='nearest')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=model.predict(img_array)\nindicies=a.argmax()\n\nif indicies == 0:\n    print(\"MRI has a giloma tumor\")\nelif indicies == 1:\n    print(\"MRI has meningioma tumor\")\nelif indicies == 2:\n    print(\"MRI has  No tumor\")\nelif indicies == 3:\n    print(\"MRI has pituitary tumor\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}